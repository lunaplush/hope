{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b53180d6-9605-4eef-bede-ded1865f002f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "import torch\n",
    "import numpy as np\n",
    "import pickle\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "\n",
    "from torchvision import transforms\n",
    "from multiprocessing.pool import ThreadPool\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "from matplotlib import colors, pyplot as plt\n",
    "\n",
    "\n",
    "# в sklearn не все гладко, чтобы в colab удобно выводить картинки\n",
    "# мы будем игнорировать warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=DeprecationWarning)\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea91723-cbf7-4be7-a8e9-bb7fe3e33738",
   "metadata": {},
   "source": [
    "### Нужно выбрать на каком устройстве будет обучать НС"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d0b8c8a-6c18-4856-b248-2c9d9c49648e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# разные режимы датасета\n",
    "DATA_MODES = ['train', 'val', 'test']\n",
    "# все изображения будут масштабированы к размеру 224x224 px\n",
    "RESCALE_SIZE = 224\n",
    "\n",
    "# работаем на видеокарте\n",
    "#DEVICE = torch.device(\"cuda\")\n",
    "\n",
    "# ИЛИ на CPU\n",
    "DEVICE=\"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6548c495-2d5b-4e46-aa70-2f400d787467",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpsonsDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Датасет с картинками, который паралельно подгружает их из папок\n",
    "    производит скалирование и превращение в торчевые тензоры\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, files, mode):\n",
    "        super().__init__()\n",
    "        # список файлов для загрузки\n",
    "        self.files = sorted(files)\n",
    "        # режим работы\n",
    "        self.mode = mode\n",
    "\n",
    "        if self.mode not in DATA_MODES:\n",
    "            print(f\"{self.mode} is not correct; correct modes: {DATA_MODES}\")\n",
    "            raise NameError\n",
    "\n",
    "        self.len_ = len(self.files)\n",
    "\n",
    "        self.label_encoder = LabelEncoder()\n",
    "\n",
    "        if self.mode != 'test':\n",
    "            self.labels = [path.parent.name for path in self.files]\n",
    "            self.label_encoder.fit(self.labels)\n",
    "\n",
    "            with open('label_encoder.pkl', 'wb') as le_dump_file:\n",
    "                pickle.dump(self.label_encoder, le_dump_file)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len_\n",
    "\n",
    "    def load_sample(self, file):\n",
    "        image = Image.open(file)\n",
    "        image.load()\n",
    "        return image\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # для преобразования изображений в тензоры PyTorch и нормализации входа\n",
    "        transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        x = self.load_sample(self.files[index])\n",
    "        x = self._prepare_sample(x)\n",
    "        x = np.array(x / 255, dtype='float32')\n",
    "        x = transform(x)\n",
    "        if self.mode == 'test':\n",
    "            return x\n",
    "        else:\n",
    "            label = self.labels[index]\n",
    "            label_id = self.label_encoder.transform([label])\n",
    "            y = label_id.item()\n",
    "            return x, y\n",
    "\n",
    "    def _prepare_sample(self, image):\n",
    "        image = image.resize((RESCALE_SIZE, RESCALE_SIZE))\n",
    "        return np.array(image)\n",
    "\n",
    "def imshow(inp, title=None, plt_ax=plt, default=False):\n",
    "    \"\"\"Imshow для тензоров\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt_ax.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt_ax.set_title(title)\n",
    "    plt_ax.grid(False)\n",
    "\n",
    "TRAIN_DIR = Path('train/simpsons_dataset')\n",
    "TEST_DIR = Path('testset/testset')\n",
    "\n",
    "train_val_files = sorted(list(TRAIN_DIR.rglob('*.jpg')))\n",
    "test_files = sorted(list(TEST_DIR.rglob('*.jpg')))\n",
    "\n",
    "\n",
    "train_val_labels = [path.parent.name for path in train_val_files]\n",
    "train_files, val_files = train_test_split(train_val_files, test_size=0.25, \\\n",
    "                                          stratify=train_val_labels)\n",
    "\n",
    "## Изменила, чтобы обучать на всем множестве\n",
    "#train_files = train_val_files\n",
    "\n",
    "val_dataset = SimpsonsDataset(val_files, mode='val')\n",
    "if val_dataset is None:\n",
    "    val_dataset = SimpsonsDataset(val_files, mode='val')\n",
    "\n",
    "train_dataset = SimpsonsDataset(train_files, mode='train')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4a7d7a-5bae-4fe1-a588-beca9992ee17",
   "metadata": {},
   "source": [
    "## Усовершенствования НС по сравнению с базовой\n",
    "1. На каждом сверточном слое сети добавим BatchNorm2d\n",
    "2. Ну уровне классификации добавим второй линейный слой для того, чтобы сделать классификатор более мощным (1000 нейронов на скрытом слое\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "982f6040-e3a9-44ca-886d-63f5c950dd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCnn(nn.Module):  \n",
    "\n",
    "    def __init__(self, n_classes):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=8, kernel_size=3),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        self.conv5 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=96, kernel_size=3),\n",
    "            nn.BatchNorm2d(96),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        self.lin1 = nn.Sequential(\n",
    "            nn.Linear(96 * 5 * 5, 1000),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.out = nn.Linear(1000, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.conv5(x)\n",
    "\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.lin1(x)\n",
    "        logits = self.out(x)\n",
    "        return logits\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b1435f8-c325-4ce4-8c4c-8aa7c6514a99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we will classify :42\n",
      "MyCnn(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv3): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv4): Sequential(\n",
      "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv5): Sequential(\n",
      "    (0): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (lin1): Sequential(\n",
      "    (0): Linear(in_features=2400, out_features=1000, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (out): Linear(in_features=1000, out_features=42, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "def fit_epoch(model, train_loader, criterion, optimizer):\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    processed_data = 0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs = inputs.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        preds = torch.argmax(outputs, 1)\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "        processed_data += inputs.size(0)\n",
    "\n",
    "    train_loss = running_loss / processed_data\n",
    "    train_acc = running_corrects.cpu().numpy() / processed_data\n",
    "    return train_loss, train_acc\n",
    "\n",
    "\n",
    "def eval_epoch(model, val_loader, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    processed_size = 0\n",
    "\n",
    "    for inputs, labels in val_loader:\n",
    "        inputs = inputs.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "\n",
    "        with torch.set_grad_enabled(False):\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            preds = torch.argmax(outputs, 1)\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "        processed_size += inputs.size(0)\n",
    "    val_loss = running_loss / processed_size\n",
    "    val_acc = running_corrects.double() / processed_size\n",
    "    return val_loss, val_acc\n",
    "\n",
    "\n",
    "def train(train_files, val_files, model, epochs, batch_size):\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    history = []\n",
    "    log_template = \"\\nEpoch {ep:03d} train_loss: {t_loss:0.4f} \\\n",
    "    val_loss {v_loss:0.4f} train_acc {t_acc:0.4f} val_acc {v_acc:0.4f}\"\n",
    "\n",
    "    with tqdm(desc=\"epoch\", total=epochs) as pbar_outer:\n",
    "        opt = torch.optim.Adam(model.parameters())\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            train_loss, train_acc = fit_epoch(model, train_loader, criterion, opt)\n",
    "            print(\"loss\", train_loss)\n",
    "\n",
    "            val_loss, val_acc = eval_epoch(model, val_loader, criterion)\n",
    "            history.append((train_loss, train_acc, val_loss, val_acc))\n",
    "\n",
    "            pbar_outer.update(1)\n",
    "            tqdm.write(log_template.format(ep=epoch + 1, t_loss=train_loss, v_loss=val_loss, t_acc=train_acc, v_acc=val_acc))\n",
    "\n",
    "    return history\n",
    "\n",
    "\n",
    "def predict(model, test_loader):\n",
    "    with torch.no_grad():\n",
    "        logits = []\n",
    "\n",
    "        for inputs in test_loader:\n",
    "            inputs = inputs.to(DEVICE)\n",
    "            model.eval()\n",
    "            outputs = model(inputs).cpu()\n",
    "            logits.append(outputs)\n",
    "\n",
    "    probs = nn.functional.softmax(torch.cat(logits), dim=-1).numpy()\n",
    "    return probs\n",
    "\n",
    "n_classes = len(np.unique(train_val_labels))\n",
    "simple_cnn = MyCnn(n_classes).to(DEVICE)\n",
    "print(\"we will classify :{}\".format(n_classes))\n",
    "print(simple_cnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e210d83-419a-4f6a-a216-d6f81025ee59",
   "metadata": {},
   "source": [
    "##  Определение режима обучения\n",
    "\n",
    "Чтобы запустить обучение с самого сначала, нужно установить TRAIN_STATUS = True и EXIST_MODEL_FILE=None,\n",
    "А чтобы работать с готовой обченной моделью, установить\n",
    "EXIST_MODEL_FILE =\"modelfile.pth\"  и TRAIN_STATUS = False\n",
    "Чтобы продолжить обучение существующей модели нужно установить\n",
    "TRAIN_STATUS = True  и EXIST_MODEL_FILE =\"modelfile.pth\"\n",
    "\n",
    "Количесво эпох задано параметром EPOCHS_CURRENT_STEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc71aa7f-83d7-4d54-9ef0-30b193a59e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "if val_dataset is None:\n",
    "    val_dataset = SimpsonsDataset(val_files, mode='val')\n",
    "\n",
    "train_dataset = SimpsonsDataset(train_files, mode='train')\n",
    "\n",
    "TRAIN_STATUS = False\n",
    "EXIST_MODEL_FILE = \"my_cnn.pth\"\n",
    "EPOCHS_CURRENT_STEP = 2\n",
    "if TRAIN_STATUS:\n",
    "    if EXIST_MODEL_FILE is not None:\n",
    "        simple_cnn.load_state_dict(torch.load(EXIST_MODEL_FILE))\n",
    "    history = train(train_dataset, val_dataset, model=simple_cnn, epochs=EPOCHS_CURRENT_STEP, batch_size=512)\n",
    "    torch.save(simple_cnn.state_dict(), \"my_cnn.pth\")\n",
    "    loss, acc, val_loss, val_acc = zip(*history)\n",
    "    plt.figure(figsize=(15, 9))\n",
    "    plt.plot(loss, label=\"train_loss\")\n",
    "    plt.plot(val_loss, label=\"val_loss\")\n",
    "    plt.legend(loc='best')\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.show()\n",
    "else:\n",
    "    simple_cnn = MyCnn(n_classes).to(DEVICE)    \n",
    "    simple_cnn.load_state_dict(torch.load(EXIST_MODEL_FILE))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "829fa8fe-a091-4d26-bb77-d4f5e6600a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = SimpsonsDataset(test_files, mode=\"test\")\n",
    "\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=64)\n",
    "probs = predict(simple_cnn, test_loader)\n",
    "label_encoder = pickle.load(open(\"label_encoder.pkl\", 'rb'))\n",
    "\n",
    "preds = label_encoder.inverse_transform(np.argmax(probs, axis=1))\n",
    "test_filenames = [path.name for path in test_dataset.files]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "#my_submit = pd.read_csv(\"gdrive/My Drive/simpsons/data/labels.csv\")\n",
    "my_submit = pd.DataFrame({'Id': test_filenames, 'Expected': preds})\n",
    "my_submit.head()\n",
    "\n",
    "my_submit.to_csv('mycnn_for_submit.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10f81a8-cb8d-4ec1-ae86-ad5692bbf314",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
